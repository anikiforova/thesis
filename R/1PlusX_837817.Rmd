---
title: "1PlusX_837817"
author: "Ana Dimitrova"
date: "7/24/2018"
output: pdf_document
---
 

```{r setup, include=TRUE, echo=FALSE}
library(ggplot2)
library(scales)
library(gridExtra)

campaign_id = 837817
path = paste("~/Documents/ETH/Thesis/1plusX/Data/Thesis/1plusx/Results/", campaign_id, "/", sep="")
path_ctr = paste("~/Documents/ETH/Thesis/1plusX/Data/Thesis/1plusx/Results/CTR/", campaign_id, "/", sep="")
plot_results <- function(algorith_name="Random") {
  
  data <- read.csv(file=paste0(path, paste0(algorith_name, ".csv")), header=TRUE, sep=",")
  data$Percent = data$Clicks / data$Impressions * 100
  data$Factor = paste(data$Method, sep=" ")

  ggplot(data, aes(x=TotalImpressions, y=Percent, colour=Factor)) + 
    stat_smooth(aes(x = TotalImpressions, y = Percent), method = "lm",
                formula = y ~ poly(x, 10), se = FALSE) +
    xlab("Impressions") + ylab("% of Clicks") +
    #expand_limits(y=c(4,7.5), x=c(0, 225000)) + 
    theme_bw() + ggtitle(algorith_name)
}

formatterM <- function(){
  function(x) paste(x/1000000, "M")
}

formatterPretty <- function(){
  function(x) ifelse(x==10, paste(x, "% (Random)"), paste(x, "%"))
}

selectNecessaryColumns <- function(df, columns) {
  for (column in columns) {
    if(!(column %in% colnames(df))){
      df[column] = NA
    } 
  }
  df[,columns]
}

prepData <- function(files, cur_path=path) {
  file=paste0(cur_path, paste0(files[1], ".csv"))
  data <- read.csv(file=paste0(cur_path, paste0(files[1], ".csv")), header=TRUE, sep=",")
  columns = c("Clicks", "Impressions", "RecommendationPart","TotalImpressions","Method", "Alpha","Timestamp","TrainPart", "MSE", "CumulativeMSE", "Nu", "Hours", "LengthScale", "ClusterCount")
  data = selectNecessaryColumns(data, columns)
  if(length(files) > 1){
    for (name in files){
      data1 <- read.csv(file=paste0(cur_path, paste0(name, ".csv")), header=TRUE, sep=",")
      data1 = selectNecessaryColumns(data1, columns)
      data <- rbind(data, data1)  
    }
  }
  data$Percent = data$Clicks / data$Impressions * 100
  data$Factor = factor(paste(data$Method, " ", data$Alpha, " R:", data$RecommendationPart * 100, sep=""))
  data$UserPercentage = factor(data$RecommendationPart * 100)
  #data$Timestamp = data$Timestamp / 1000
  data$Timestamp = as.POSIXct(data$Timestamp, origin="1970-01-01")
  data
}
  
g_legend<-function(a.gplot){
  tmp <- ggplot_gtable(ggplot_build(a.gplot))
  leg <- which(sapply(tmp$grobs, function(x) x$name) == "guide-box")
  legend <- tmp$grobs[[leg]]
  return(legend)}

plotGroup <- function(g1, g2, title) {
  mylegend<-g_legend(g2)
  grid.arrange(arrangeGrob(g1 + theme(legend.position="none"),
                           g2 + theme(legend.position="none"),
                                 nrow=1, ncol=2, widths=unit(c(9, 9), "cm"), heights=unit(9, "cm")),
                mylegend, nrow=2, widths=unit(18, "cm"), heights=unit(c(9, 1), "cm"),
                top = title)
}

getCTRPlot <- function(data, limits = c(0,1.5)) {
  g1 = ggplot(data, aes(x=TotalImpressions, y=Percent, colour=Factor)) + 
    geom_line() +
    xlab("Impressions") + ylab("CTR") +
    expand_limits(y=limits) + 
    scale_x_continuous(labels=formatterM()) + 
    theme_bw() 
  
  g1
}

getMSEPlot <- function(data, xLimit, scaleName) {
  g2 = ggplot(data, aes(x=TotalImpressions, y=MSE, colour=Factor)) + 
  stat_smooth(aes(y=MSE, colour=Factor), method = "lm", formula = y ~ poly(x, 10), se = FALSE) +
    xlab("Impressions") + ylab("MSE") +
    expand_limits(y=xLimit) + 
    scale_x_continuous(labels=formatterM()) +
    theme_bw() +
    theme(legend.position="bottom")+
    scale_color_discrete(name=scaleName)
  g2
}
  
```

Comparison between CTR and MSE for Random when for assignment are used discrete values - {0,1} or float between [0, 1]. When doing the math for uniform distribution it's clear that the expectation should be a bit above 33% (since we have very few 1s we can approximate the error if we get only 0s). E[(0 - A)^2] = E[0^2] - E[0*A] + E[A^2] = var(A) + E[A]^2 = 1/12 + 1/4 = 1/3
And the expectation for the discrete values {0, 1} is clearly 0.5%. 
In terms of CTR both perform equally around 0.18.
```{r Random, include=TRUE, echo=FALSE}

files =  c("Random")
data = prepData(files)
data$Factor = factor(paste(data$Method," R:", data$RecommendationPart*100, "%", sep=""))

g1 = getCTRPlot(data)
g2 = getMSEPlot(data, c(0,1), "Model/Rec Size")

plotGroup(g1, g2, "Random - Evaluation of Rec. size and sampling choices.")
```


```{r Regression_Alphas, include=TRUE, echo=FALSE}

files =  c("Regression")
data = prepData(files)
data$Factor = factor(paste(substr(data$Method, 1, 3), "% A:", data$Alpha, sep=""))

data = subset(data, Impressions > 1000 & !(Method == "Random" & RecommendationPart== 0.05)
              & (Method %in% c("Regression","Random")))

g1 = getCTRPlot(data)
g2 = getMSEPlot(data, c(0,0.005), "Method/Alpha")

plotGroup(g1, g2, "Regression Rec:2% - Evaluation of Alpha values ")
```
This plot shows how equalizing the clicks affects performance. Both MSE and CTR get worse once we try to balance the number of clicks with the number of no clicks. The increase in MSE is expected since the model will be more optimistic in the ctr ration therefore we will predict generally larger values. However the CTR also suffers. The assumption at the moment is that that is caused by overfitting. 
Currently the resampling is done on the whole set of clicks, and updated strategy might include adding age to the clicks so that the more recent clicks are resampled more often than older ones.
```{r Regression_Equalize, include=TRUE, echo=FALSE}
files =  c("Regression")
data = prepData(files)
data$Method =  lapply(data$Method, as.character)
data$Eq = lapply(data$Method, function(m) { if(grepl("_E_", m)) paste("E:",substr(m, nchar(m)-2, nchar(m)), sep="") else "" })

data$Factor = factor(paste("A:",data$Alpha, " ", data$Eq, sep=""))
data = subset(data, Impressions > 1000 & Alpha %in% c(0.001, 0.01))
g1 = getCTRPlot(data)
g2 = getMSEPlot(data, c(0,0.005), "Method/Alpha")

plotGroup(g1, g2, "Regression Rec:2% - Evaluation of click resampling")

```
This plot shows the effect of changing the update time - from the standard 1h to 4h. The plot shows not great differences in performance. In the begginning 4h presents a bit better results since it's using bigger set of data points to create the model, but from there on it becomes less flexibable to the 1h model and deteriorates slightly in performance compared to 1h model. The analysis holds when performed on both 2% and 5% recommendation size.
```{r LinUCB_Hours, include=TRUE, echo=FALSE}

files =  c("LinUCB_Disjoint")
data = prepData(files)
data$Eq = lapply(data$Method, function(m) { if(grepl("_H_", m)) "12h" else "1h" })

data$Factor = factor(paste("R:",data$RecommendationPart *100, "% ", data$Eq, sep=""))

data = subset(data, Impressions > 1000 & (grepl("_H_", Method) | (Method == "LinUCB_Disjoint" & RecommendationPart %in% c(0.02, 0.05) & Alpha == 0.02)))

g1 = getCTRPlot(data)
g2 = getMSEPlot(data, c(0,0.003), "Rec. Size/Hours")

plotGroup(g1, g2, "LinUCB Rec:2% - Evaluation of #Hours between update")
```
```{r GP_Clustered, include=TRUE, echo=FALSE}

files =  c("GP_Clustered", "GP_Clustered_Matern", "GP_Clustered_RBF", "Random")
data = prepData(files)

data$Factor = factor(paste(data$Method," A:", data$Alpha, sep = ""))

data = subset(data, Impressions > 1000 & ((RecommendationPart == 0.2 & (Alpha == 1 | is.na(Alpha))) | Method == "Random_H_12"))

g1 = getCTRPlot(data, c(0,0.75)) 
data = subset(data, Method != "Random_H_12")
g2 = getMSEPlot(data, c(0,0.003), "Rec. size")

plotGroup(g1, g2, "GP Evaluation of parameters and kernels")
```
```{r GP_Clustered, include=TRUE, echo=FALSE}

files =  c("GP_Clustered_New")
data = prepData(files)

data$Factor = factor(paste(" Nu:", data$Nu, " H:", data$Hours, " LS:", data$LengthScale, " CL:", data$ClusterCount, sep = ""))

data = subset(data, Impressions > 1000)

g1 = getCTRPlot(data, c(0,0.75)) 
g2 = getMSEPlot(data, c(0,0.003), "")

plotGroup(g1, g2, "GP Evaluation of parameters and kernels")
```


This plot aims to show the behavior of LinUCB (and by proxy other linear algos) with changing recommendation size. Clearly the algorithm recommendations become worse the bigger the recommendation list is.
Executed with fixed alpha = 0.02 which is the one that has displayed best results so far.
```{r Regression, include=TRUE, echo=FALSE}

files =  c("LinUCB_Disjoint")
data = prepData(files)
data$Factor = factor(paste(substr(data$Method, 1, 6), " R:", data$RecommendationPart*100, "%", sep = ""))
data = subset(data, Impressions > 1000 & ((Method == "Random" & RecommendationPart == 0.02) | ( Method == "LinUCB_Disjoint" & Alpha == 0.02)))
g1 = getCTRPlot(data)
g2 = getMSEPlot(data, c(0,0.003), "Method/Rec. Size")

plotGroup(g1, g2, "LinUCB Alpha:0.02 - Evaluation of Rec. Size")
```
```{r TS_Lin, include=TRUE, echo=FALSE}

files =  c("TS_Lin")
data = prepData(files)

data$Factor = factor(paste(data$Method, "% A:", data$Alpha, sep = ""))
data = subset(data, Impressions > 1000 & Method == "TS_Lin" & RecommendationPart == 0.02)
g1 = getCTRPlot(data)
g2 = getMSEPlot(data, c(0,0.003), "Method/Alpha")

plotGroup(g1, g2, "TS_Lin Rec:2% - Evaluation of best Alpha")
```
```{r TS_Lin, include=TRUE, echo=FALSE}

files =  c("TS_Lin")
data = prepData(files)

data$Factor = factor(paste(data$Method, " R:", data$RecommendationPart * 100, "%", sep = ""))
data = subset(data, Impressions > 1000 & Method == "TS_Lin" & Alpha == 0.0001)

g1 = getCTRPlot(data)
g2 = getMSEPlot(data, c(0,0.003), "Method/Rec. size")

plotGroup(g1, g2, "TS_Lin Alpha:0.02 - Evaluation of rec. size")
```

```{r TS_Lin, include=TRUE, echo=FALSE}

files =  c("TS_Lin")
data = prepData(files)
data$Method =  lapply(data$Method, as.character)
data$Eq = lapply(data$Method, function(m) { if(grepl("_E_", m)) paste("E:",substr(m, nchar(m)-2, nchar(m)), sep="") else "" })

data$Factor = factor(paste(substr(data$Method, 1, 6), " ", data$Eq, sep = ""))
data = subset(data, Impressions > 1000 & RecommendationPart == 0.02 & Alpha == 0.0001)
g1 = getCTRPlot(data)
g2 = getMSEPlot(data, c(0,0.05), "Method")

plotGroup(g1, g2, "TS_Lin Rec:2% - Evaluation of click resampling")
```

```{r all, include=TRUE, echo=FALSE}

files =  c("TS_Lin", "Regression", "LinUCB_Disjoint")
data = prepData(files)
data$Factor = factor(paste(substr(data$Method, 1, 6), " A:", data$Alpha, sep = ""))

data = subset(data, Impressions > 1000 & RecommendationPart == 0.02 &
                 ((Method == "TS_Lin"           & Alpha == 0.001) |
                  (Method == "Regression"       & Alpha == 0.01) |
                  (Method == "LinUCB_Disjoint"  & Alpha == 0.02) ))

g1 = getCTRPlot(data)
g2 = getMSEPlot(data, c(0,0.003), "Method/Alpha")

plotGroup(g1, g2, "Comparison algos with best params")
```

```{r all, include=TRUE, echo=FALSE}

files =  c("TS_Lin", "NN", "LinUCB_Disjoint", "Regression", "GP_Clustered")
data = prepData(files)
data$Factor = factor(data$Method)

data = subset(data, Impressions > 1000 & RecommendationPart == 0.02 &
                 ((Method == "TS_Lin"           & Alpha == 0.001) |
                  (Method == "Regression"       & Alpha == 0.01) |
                  (Method == "LinUCB_Disjoint"  & Alpha == 0.02) |
                  (Method == "NN_E_0.8"         & Alpha == 0.0001) |
                  (Method == "GP_Clustered_E_0.8"& Alpha == 1.2)
                    ))

ggplot(data, aes(x=Timestamp, y=Impressions, colour=Factor)) + 
    geom_line() +
    xlab("Timestamp") + ylab("Cumulative Common Impressions") +
    scale_y_continuous(labels=formatterM()) +
    theme_bw() +
    ggtitle("Cumulative # Impressions during Exploration Scavanging")
  
``` 
