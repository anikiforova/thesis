---
title: "Algorithm comparison"
author: "Ana Dimitrova"
output: pdf_document

---
 

```{r setup, include=TRUE, echo=FALSE}
library(ggplot2)
library(scales)
library(gridExtra)

source("~/Documents/ETH/ASL/ASL_Middleware/analysis/R/External.R")
path = "~/Documents/ETH/Thesis/1plusX/Data/Thesis/Simulation/Results/"
plot_results <- function(algorith_name="Random") {
  
  data <- read.csv(file=paste0(path, paste0(algorith_name, ".csv")), header=TRUE, sep=",")
  data$Percent = data$Clicks / data$Impressions * 100
  data$Factor = paste(data$Method, data$Alpha, sep=" ")

  ggplot(data, aes(x=Impressions, y=Percent, colour=Factor)) + 
  geom_line() + xlab("Impressions") + ylab("% of Clicks") +
  expand_limits(y=c(4,7.5), x=c(0, 75000)) + theme_bw() + ggtitle(algorith_name)
}
  
```

Simulation using real embeddings from 1plusX with simulated clicks.
Used randomly generated theta for evaluating the click value.
The click result = user.dot(theta) + error.
Clearly linear correlation and therefore very good results with linear regression. 

```{r linucb-hybrid, include=TRUE, echo=FALSE}
algorith_name="Simulation_Results"
data <- read.csv(file=paste0(path, paste0(algorith_name, ".csv")), header=TRUE, sep=",")
data$Percent = data$X7 / data$X100 * 100
data$Factor = paste(data$SRandom, data$X0.00, sep=" ")

ggplot(data, aes(x=X100, y=Percent, colour=Factor)) + 
geom_line() + xlab("Impressions") + ylab("% of Clicks") +
expand_limits(y=c(0,100), x=c(0, 20000)) + theme_bw()  + ggtitle("Linear - CTR: 5% - No added randomization")
  
```
Using a more complicated click function =sigma( A.dot(user^2) + B(user) + C ) + error
However clearly this is still not very sophisticated function. Still very good results with using a simple regression model.
CTR - 5% 
Using SEGreedy with a different exploration percentage. Interestingly the larger exploration the worse results. 
```{r gpprank, include=TRUE, echo=FALSE}
algorith_name="Simulation_Results_Poly"
data <- read.csv(file=paste0(path, paste0(algorith_name, ".csv")), header=TRUE, sep=",")
data$Percent = data$X4 / data$X100 * 100
data$Factor = paste(data$SRandom, data$X0.00, sep=" ")

ggplot(data, aes(x=X100, y=Percent, colour=Factor)) + 
geom_line() + xlab("Impressions") + ylab("% of Clicks") +
expand_limits(y=c(0,100), x=c(0, 10000)) + theme_bw() + ggtitle("Polynomial + Sigmoid - CTR: 5% - No added randomization")
```
Similarly to above, but adding more substantial error. 
The error takes random 5% of the generated clicks and flips them ot no click and takes same amount of no-clicks and makes them clicks. 

Also reducing the size of the CTR so that we can see more real world CTR for ads. 
The number of impressions this is equal to 70% of the total clicks. If an user is selected then he could not be chosen again, so we know that past 100% of clicks the ctr would fall drastically and no need to test that.

Clearly the lower CTR affects learning rate and results in a lower CTR, however it still performs quite well. 

```{r Poly_Sigmoid, include=TRUE, echo=FALSE, fig.height = 4, fig.width = 12 }
algorith_name<-"Poly_Sigmoid"
data <- read.csv(file=paste0(path, paste0(algorith_name, ".csv")), header=TRUE, sep=",")

data$Percent = data$ClickCount / data$Impressions * 100
data$Algorithm = paste(data$AlgoName)
data_non_random = data[data$AlgoName != "SRandom",]

groupedData <- summarySE(data_non_random, 
            measurevar=c("Percent"),
            groupvars=c("Impressions", "AlgoName", "Alpha", "OverallCTR", "Algorithm"))

p1 = ggplot(groupedData[groupedData$OverallCTR ==0.005,], aes(Impressions, y=mean, colour=Algorithm)) + 
  geom_ribbon(aes(ymin=mean-se, ymax=mean+se, linetype=NA), alpha=.3) +
  expand_limits(y=c(0,100)) +
  geom_line() + xlab("Impressions") + ylab("% of Clicks") +
 theme_bw() + ggtitle("CTR: 0.5%")+ theme(legend.position="bottom",legend.direction="horizontal")

p2 = ggplot(groupedData[groupedData$OverallCTR ==0.01,], aes(Impressions, y=mean, colour=Algorithm)) + 
  geom_ribbon(aes(ymin=mean-se, ymax=mean+se, linetype=NA), alpha=.3) +
  expand_limits(y=c(0,100)) +
  geom_line() + xlab("Impressions") + ylab("% of Clicks") +
 theme_bw() + ggtitle("CTR: 1%") 

p3 = ggplot(groupedData[groupedData$OverallCTR ==0.02,], aes(Impressions, y=mean, colour=Algorithm)) + 
  geom_ribbon(aes(ymin=mean-se, ymax=mean+se, linetype=NA), alpha=.3) +
  expand_limits(y=c(0,100)) +
  geom_line() + xlab("Impressions") + ylab("% of Clicks") +
 theme_bw() + ggtitle("CTR: 2%")  + theme(legend.position="bottom",legend.direction="horizontal")

g_legend2<-function(a.gplot){
  tmp <- ggplot_gtable(ggplot_build(a.gplot))
  leg <- which(sapply(tmp$grobs, function(x) x$name) == "guide-box")
  legend <- tmp$grobs[[leg]]
  return(legend)
  }

mylegend <- g_legend2(p1)
grid.arrange(arrangeGrob(p1 + theme(legend.position="none"),
                         p2 + theme(legend.position="none"),
                         p3 + theme(legend.position="none"),
                        nrow=1, ncol=3, widths=unit(c(9, 9, 9), "cm"), heights=unit(9, "cm")),
                   mylegend, nrow=2, widths=unit(27, "cm"), heights=unit(c(9, 1), "cm"))


#ggsave(paste(imageLocation,"Experiment4Write.png", sep=""), plot=p4, width = 20, height = 10, units = "cm")

```

Exploring using an iterative algorithm instead of learning from scratch with linear regression. 
Using SGDRegressor. The results are worse, but not that drastically. Could be used in a long term evaluation for a large amount of data.
```{r Poly_Sigmoid_CGD, include=TRUE, echo=FALSE, fig.height = 4, fig.width = 12 }
algorith_name<-"Poly_Sigmoid_SGD"
data <- read.csv(file=paste0(path, paste0(algorith_name, ".csv")), header=TRUE, sep=",")

data$Percent = data$ClickCount / data$Impressions * 100
data$Algorithm = paste(data$AlgoName)
data_non_random = data[data$AlgoName != "SRandom",]

groupedData <- summarySE(data_non_random, 
            measurevar=c("Percent"),
            groupvars=c("Impressions", "AlgoName", "Alpha", "OverallCTR", "Algorithm"))

p1 = ggplot(groupedData[groupedData$OverallCTR ==0.005,], aes(Impressions, y=mean, colour=Algorithm)) + 
  geom_ribbon(aes(ymin=mean-se, ymax=mean+se, linetype=NA), alpha=.3) +
  expand_limits(y=c(0,100)) +
  geom_line() + xlab("Impressions") + ylab("% of Clicks") +
 theme_bw() + ggtitle("CTR: 0.5%")+ theme(legend.position="bottom",legend.direction="horizontal")


p2 = ggplot(groupedData[groupedData$OverallCTR ==0.01,], aes(Impressions, y=mean, colour=Algorithm)) + 
  geom_ribbon(aes(ymin=mean-se, ymax=mean+se, linetype=NA), alpha=.3) +
  expand_limits(y=c(0,100)) +
  geom_line() + xlab("Impressions") + ylab("% of Clicks") +
 theme_bw() + ggtitle("CTR: 1%") 

p3 = ggplot(groupedData[groupedData$OverallCTR ==0.02,], aes(Impressions, y=mean, colour=Algorithm)) + 
  geom_ribbon(aes(ymin=mean-se, ymax=mean+se, linetype=NA), alpha=.3) +
  expand_limits(y=c(0,100)) +
  geom_line() + xlab("Impressions") + ylab("% of Clicks") +
 theme_bw() + ggtitle("CTR: 2%")  + theme(legend.position="bottom",legend.direction="horizontal")

g_legend2<-function(a.gplot){
  tmp <- ggplot_gtable(ggplot_build(a.gplot))
  leg <- which(sapply(tmp$grobs, function(x) x$name) == "guide-box")
  legend <- tmp$grobs[[leg]]
  return(legend)
  }


mylegend <- g_legend2(p1)
grid.arrange(arrangeGrob(p1 + theme(legend.position="none"),
                         p2 + theme(legend.position="none"),
                         p3 + theme(legend.position="none"),
                        nrow=1, ncol=3, widths=unit(c(9, 9, 9), "cm"), heights=unit(9, "cm")),
                   mylegend, nrow=2, widths=unit(27, "cm"), heights=unit(c(9, 1), "cm"))


#ggsave(paste(imageLocation,"Experiment4Write.png", sep=""), plot=p4, width = 20, height = 10, units = "cm")

```

